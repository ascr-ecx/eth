This project contains code for testing various configurations for in-situ visualization.   After cloning,
cd into the root of the source tree (lets call it ROOT) and run:

git submodule update --init --recursive

to load the code for pvol, pvol-icet and pvol-ospray.

Before this can be built, you'll need to download ispc from https://ispc.github.io/downloads.html  
I've been using version 1.9.1   After you've downloaded the tar.gz file, untar it somewhere and put
the root directory of the install in your PATH environment variable.   You should then be able to
type `which ispc` and get the location of the ispc executable.

To build, configure and build pvol-icet and pvol-ospray first.   There are scripts in configs/maverick
which show the cmake setup used to build on Maverick.   cd into each directory, mkdir a build 
subdirectory, cd into it and look at ROOT/config/maverick/{pvol-icet.cmake, pvol-ospray.cmake, 
pvol.cmake} to see the cmake variables you need to consider.   Those are set up to install the 
code in the 'install' subdir of the ROOT directory.

Once the code is built, put ROOT/install/bin in your PATH environment variable and ROOT/install/lib
and ROOT/install/lib64 in your LD_LIBRARY_PATH (or DYLD_LIBRARY_PATH on mac)

Examples

module load vtk paraview

In ROOT/test, ./mkdata.py will create wavelet vtkUnstructuredGrid and vtkImageData datasets.

First we'll render a simple image of the ImageData dataset.   This use of the code only 
handles an extended version of Intel OSPRay's .vol/.raw format, so we use the vti2raw script 
to convert wavelet.vti to wavelet.vol and wavelet.raw.   This script expects the name of the 
.vti file and the variable to extract:

vti2raw wavelet.vti RTData

This will produce wavelet.raw, containing a binary brick-of-floats, and wavelet.vol, 
containing the datatype, origin, counts, stepsize, and a pointer to the raw data:

float
0.000000 0.000000 0.000000
21 21 21
1.000000 1.000000 1.000000
wavelet.raw

State

The state executable is a wrapper of the visualization code that can be run in serial or
parallel, and which can be connected to the simulator or simply load data from a .vol/.raw 
file.   It is run:

state state.json [-s w h] [-R | -V] 

where:  
	-s w h       specifies the default (1920x1080)
	-R           use the raycaster renderer
	-V           use the VTK-based renderer (default)

state.json specifies the visualization to be performed, and identifies the dataset, 
isovalues and clipping planes, transfer functions, camera parameters etc.   An example, in
ROOT/test/wavelet.json, is:

{
    "DataModel": {
        "volumes": [
            {
                "filename": "wavelet.vol",
                "isovalues": "1 130",
                "slices": "2 1 0 0 10 0 0 1 1",
                "transfer function": {
                    "color map": "3 0 0 1 0.5 0 1 0 1 1 0 0",
                    "opacity map": "3 0 1 0.5 1 1 1"
                }
            }
        ]
    },
    "Camera": {
        "viewpoint": "30 35 50",
        "viewdirection": "-20 -25 -40",
        "viewup": "0 1 0",
        "aov": "110"
    },
    "Lighting": {
        "lights": "1 0.485071 -0.727607 -0.485071",
        "shadows": "off",
        "Ka": "0.5",
        "Kd": "0.5",
        "ambient occlusion": "0 1"
    }
}

This state file loads 'wavelet.vol', sets an isovalue at 140, two slicing planes, one perpendicular to the X axis at X == 10, and one perpendidicular to the Z axis at Z == 1, a lighting environment and a camera.

Given the -V parameter (or let to default) state will use the VTK visualization backend and produce vtk.png.   Given the -R parameter instead, it will use the raycasting backend and produce raycast.png.

Run under MPI, state will partition the block of values and run one partition in each process.   Selecting an appropriate number of processes - e.g. one that nicely factors into three - is advised.

Cinema

Cinema behaves much like state, except that it (currently) hard-codes the variance of several properties to create Cinema dataset.





